## Introduction

Hello there and welcome to our Stream Video Android tutorial.

`StreamVideo` is an SDK that facilitates adding calling (audio and video) support to your apps. It's a performant and highly customizable, allowing you to build various types of calling applications and streaming use cases, such as:

* **Messenger-style applications**: These applications implement Chat as a primary source of communication, with Video secondary.
* **Zoom-style applications**: Such apps focus primarily on Video, with Chat as a way to communicate while in a call.
* **Audio Rooms**: Our SDK allows you to build audio-only rooms that allow live communication, such as Twitter Spaces.
* **Livestreaming**: We support one of the most popular modern use cases - streaming audio and video to audiences. You can replicate apps like Twitch or YouTube Live.

This makes the Stream Video SDK the best-in-class choice when integrating Audio and Video communication in your apps. With all that in mind, let's dive into the tutorial.


## Tutorial Content

In this tutorial we'll cover the main steps required to produce a fully capable video chat app, using **Stream Video**. The application you're building is called `VideoTutorial` (fitting, I know), and its features will be the following:

- Creating a project & setting up Stream dependencies
- Authenticating the user
- Handling Stream Video lifecycle
- Creating & joining a Call
- Rendering Call UI and controls

By the end of the tutorial, you'll be more than capable of building an app that powers video calls, with deep knowledge of how our internal state management works. The app has only a couple of screens to choose a Call ID and to participate in the call:

| HomeActivity                                                 | CallActivity                  |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| ![Home Activity UI](https://user-images.githubusercontent.com/17215808/200299040-93396c6b-41ba-4020-895a-eb22058983d0.png) | ![Call Screen](https://user-images.githubusercontent.com/17215808/202099515-90ca68f0-fea6-4be8-a7d9-df590d6f357b.png) |

If you're interested in what the application looks like and a small demo of how it works, make sure to check out the full sample app or the video that walks through it below.

// TODO - video

Once you're ready, we can start with the project.

## Starting the Project

> **Note**: In this tutorial, we'll be using Compose for the UI, but you can very much build this in XML too. Our state is pragmatic and can be integrated with the UI toolkit you prefer.
>
> Additionally, the completed app for each step of the tutorial is available on GitHub. // TODO

To get started with [Stream Video](https://github.com/GetStream/stream-video-android), we have a great starter project // TODO that pre-bakes all the boilerplate UI and dependency code for you.

* Make sure to clone the starter project, using its repository. // TODO
* Open the starter project and let it sync the dependencies.

Once you clone and load the project, you need to add the appropriate Stream Video dependencies. For now, we'll add the core dependency which enables the use of our **low-level-client** and the **WebRTC** wrappers.

Our SDKs are available from MavenCentral, and everything you need to align with our SDK in terms of the Kotlin and Compose versions is already prepared in the starter project.

Now that you have the project ready, add the Stream dependencies. Open your `app` module's `build.gradle` file and add the following:

```groovy
dependencies {
    implementation "io.getstream:stream-video-android:1.0.0"
}
```

This dependency holds all the necessary code to authenticate a user, start a Stream Video client, create or join a call and connect to the call to start receiving audio and video tracks.

Now that you've verified the project and added the Stream dependency, you can start with **user authentication**.

## Authenticating the User

To fully connect to the Stream Video API, you need to authenticate a user. Using our backend documentation // TODO for reference you should be able to obtain a user token that contains all the information about a given user in your app.

On top of that, for video, Stream provides a [low-level client](.../04-client/01-overview.mdx) and both [XML](03-ui/04-xml/01-overview.mdx) and [Compose](03-ui/03-compose/01-overview.mdx) UI components to help you integrate video chat features. We'll touch upon UI later in the tutorial - for now, let's first create our Client.

Once you have the token and other user credentials ready, by authenticating against your backend, it's time to create the Stream Video Client.

Open the file called `VideoApp.kt` and replace the class contents with the following:

```kotlin
class VideoApp : Application() {

    // 1 
    private var credentials: CredentialsProvider? = null
    private var client: StreamVideo? = null
    
    val credentialsProvider: CredentialsProvider
        get() = requireNotNull(credentials)

    val streamVideo: StreamVideo
        get() = requireNotNull(client)

    /**
     * Sets up and returns the [streamVideo] required to connect to the API.
     */
    fun initializeStreamVideo( // 2
        credentialsProvider: CredentialsProvider,
        loggingLevel: LoggingLevel
    ): StreamVideo {
        this.credentials = credentialsProvider

        return StreamVideoBuilder(
            context = this,
            credentialsProvider = credentialsProvider,
            loggingLevel = loggingLevel,
        ).build().also {
            client = it
        }
    }

    // 3
    fun logOut() {
        streamVideo.clearCallState()
        calls = null
    }
}
```

This class represents the main entry point for your app. You'll use it to achieve the following:

1. Persist the `StreamVideo` client and the  `CredentialsProvider` that let you connect to calls.

2. Call `initializeStreamVideo()` with a `CredentialsProvider` and `LoggingLevel` for our internal loggers, to initialize the Stream API.
3. Use `logOut` to clear the client state, when you want to change the user.
4. Access the `VideoApp` through `Context` to fetch the Stream client.

Now, open the `MainActivity` and replace the `onCreate()` with the following:

```kotlin
class MainActivity : AppCompatActivity() {

    override fun onCreate(savedInstanceState: Bundle?) {
        super.onCreate(savedInstanceState)
        authenticateUser() // here
        setContent {
            VideoTheme { // here
                HomeScreen()
            }
        }
    }
}
```

To start off, you've added a call to `authenticateUser()`, where you'll set up the necessary credentials to connect to our API.

> **Note**: In real scenarios, your backend would provide these credentials after you log in into your API.

You also wrapped the `HomeScreen()` with our `VideoTheme` that provides colors, text styles, icons and more, for customization. Make sure to check out our [VideoTheme documentation](TODO) to learn more.

Now let's complete `authenticateUser()`. Add the following code to implement the function:

```kotlin
private fun authenticateUser() {
    val token = "hardcoded-token"
    val user = User(
        "hardcoded-id",
        "admin",
        "Tutorial Droid",
        token,
        "hardcoded image",
        emptyList(),
        emptyMap()
    )

    videoApp.initializeStreamVideo( // authenticate the user and create a client
        AuthCredentialsProvider(
            apiKey = "hardcoded-api-key", 
            userToken = token,
            user = user
        ),
        loggingLevel = LoggingLevel.BODY
    )
}
```

It's quite simple to create the main Stream Video client. You just pass in the `CredentialsProvider` that keeps track of your user token and ID.

`StreamVideo` allows you to do many different things with our API:

- Create new Calls
- Look up Calls by ID
- Join Calls
- Invite participants to a Call
- Register for Push Notifications
- Connect to a Call and initialize WebRTC handles
- Observe Call state
- ...and much more.

It's important to keep track of the `StreamVideo` instance, because it's not a singleton. We recommend keeping it in your `Application` class and initializing it whenever your users are ready to use video chat features. This gives you control over its lifecycle and lets you free up memory whenever your users don't use Video.

Now that you've added the code to create the client, you can move onto the UI part. 

## Creating Calls

For the UI, we've prepared a simple screen which lets the user write down a call ID that they want to join, as well as a button that lets them trigger an API call and get the call details. The code itself is not related to the way Stream Video works, so we'll skip over the explanation.

But we do have a couple of places in the code that you need to connect to the Stream API. First, add the following code to `logOut()`:

```kotlin
private fun logOut() {
    videoApp.logOut() // here
    finish()
}
```

It's important to clear the state of the client whenever you log out, so we call the predefined function that does that for us, in `VideoApp`. Next, fill in the `joinCall()` with the following:

```kotlin
private fun joinCall(callId: String) {
    lifecycleScope.launch { // 1
        loadingState.value = true
        val result = videoApp.streamVideo.joinCall( // 2
            type = "default", id = callId
        )
        loadingState.value = false
        result.onSuccess { // 3
            startActivity(
                CallActivity.getIntent(
                    this@HomeActivity,
                    CallInput(
                        callCid = it.call.cid,
                        callType = it.call.type,
                        callId = it.call.id,
                        callUrl = it.callUrl,
                        userToken = it.userToken,
                        iceServers = it.iceServers
                    )
                )
            )
        }
        result.onError { // 4
            Toast.makeText(this@MainActivity, it.message, Toast.LENGTH_SHORT).show()
        }
    }
}
```

There are a few parts of the flow:

1. You launch a coroutine to process the API request. All of our Video calls are powered by coroutines to make them perform as efficient and fast as possible.
2. You call `joinCall()` with a hard coded call type and the user-provided ID.
3. If the result of the request is successful, you start the `CallActivity`. We already provide this for you, but we'll need to add the video content as well as the `CallInput` parameter to `getIntent()`.
4. If the request failed, you show a small toast with the failed message, to the user.

To complete this part of the flow, head over to `CallActivity` and replace `getIntent()` with the following:

```kotlin
internal fun getIntent(
    context: Context,
    callInput: CallInput // here
): Intent {
    return Intent(context, CallActivity::class.java).apply {
        putExtra(CallActivity.KEY_CALL_INPUT, callInput) // here
    }
}
```

To make sure your `CallActivity` starts with the appropriate data, you add `CallInput` to its parameters and the `Intent` you use to start the screen with.

If you build and run your app now, you'll see the following:

![Home Activity UI](https://user-images.githubusercontent.com/17215808/200299040-93396c6b-41ba-4020-895a-eb22058983d0.png)

Try writing in a call ID and clicking the "Join Call" button. If everything goes well, you should see the progress bar show up, then a new screen being started, currently with no content.. 

If this is what happens - you've successfully integrated the first two steps of the tutorial. Next, you'll connect to the call and render its UI. Let's do it.

## Rendering the Call

Now that you've connected the join call flow, you need to render the Call state and UI. Most of the `CallActivity` is already prepared for you, but there are still a few missing pieces.

Start off by adding the following properties at the top of the class to initialize the underlying `ViewModel` and state:

```kotlin
class CallActivity : AppCompatActivity() {

    private val input: CallInput by lazy { // 1
        requireNotNull(intent.getSerializableExtra(KEY_CALL_INPUT) as? CallInput)
    }

    private val factory by lazy { // 2
        CallViewModelFactory(
            input,
            videoApp.streamVideo,
            videoApp.credentialsProvider
        )
    }

    // ViewModel
    private val callViewModel by viewModels<CallViewModel>(factoryProducer = { factory })
}
```

These properties are vital:

1. You read the `CallInput` of the `Activity` from its `Intent`, to have information such as the `callId`, `callUrl`, the `userToken` and `iceServers` used to connect to audio and video tracks.
2. You set up a `ViewModelFactory` that'll help you build our `CallViewModel` which contains all the call state as well as various handlers for muting tracks and changing audio and video devices.

Now that you have the `CallViewModel`, you can render the UI based on its state. Do that by changing `onCreate()` to the following:

```kotlin
override fun onCreate(savedInstanceState: Bundle?) {
    super.onCreate(savedInstanceState)

    setContent {
        VideoCallContent(callViewModel, onLeaveCall = ::leaveCall) // here
    }
}
```

After building the `CallViewModel` you set the content of the screen using `VideoCallContent`, our ready-bake component that helps you render the call UI with a single line of code.

When pressing back, you delegate the responsibility to `leaveCall()` to clean up the call state and finish the `CallActivity`. Make sure to also change the `leaveCall()` to the following:

```kotlin
private fun leaveCall() {
    callViewModel.leaveCall()
    finish()
}
```

Now the callback will correctly let the `ViewModel` know it's time to clean up the state, if the user decides to go back. To finalize the flow, also replace the `startVideoFlow()` function with the following:
```kotlin
private fun startVideoFlow() {
    val isInitialized = callViewModel.isVideoInitialized.value
    if (isInitialized) return
    callViewModel.connectToCall()
}
```

Now that part of the flow will successfully let the `ViewModel` know it's time to set up and connect to the call as a participant.

If you look around the `CallActivity`, there is a lot of other code there - mainly for handling permissions. Let's quickly see why this is important. 

## Handling Permissions

A vital part of the Call flow is asking users for permission to use different services their phones provide. In the case of video calling, there are several important permissions to consider, that the Stream SDK might use:

* **Camera & Audio Recording** - it seems obvious, but we need to access user's camera and microphone to send their video/audio to other participants. Users can choose to opt out of both and not send anything, or just send one.
* **Bluetooth & Audio Settings** -  Bluetooth and audio settings management is useful to let the user choose which devices they want to use for playback and recording.
* **Internet** - We need to connect to an API to communicate, but we also need to listen to connectivity changes to reflect that to the user. _These don't need to be requested in the runtime._
* **Utility** - There are some utility permissions that we request, such as vibration to signal users about calls, foreground services and full-screen Intents, to show the call state when it's in the background or if the user receives a call invite while the screen is locked. _These don't need to be requested in the runtime._

In the `CallActivity` we just request the camera and microphone permissions, but based on your use case, make sure to cover the permissions that suit your implementation.

Finally, build and run the app and you should be able to join a call and send both audio and video with respective permissions. :]

![Call Screen](https://user-images.githubusercontent.com/17215808/202099515-90ca68f0-fea6-4be8-a7d9-df590d6f357b.png)