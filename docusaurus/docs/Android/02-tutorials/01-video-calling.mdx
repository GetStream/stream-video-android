---
title: Video Call Tutorial
description: How to build a video call similar to Zoom or facebook messenger
---

import { TokenSnippet } from '../../../shared/_tokenSnippet.jsx';


Video Calling tutorial issues June 14th:

* video Renderer fallback is ugly (Jaewoong)
* standalone join button (Jeroen)
* Step 7: OnCallAction adds complexity that isn't needed.
* Step 6 or 7: We don't explain well which UI components are available (Jaewoong to check my notes below)
* Step 7: CallContainer, we should drop the "call" prefix in the arguments. IE callContainer.callAppBarContent -> callContainer.appBarContent
* review sessions with teams (Thierry)

This tutorial teaches you how to build Zoom/Whatsapp style video calling for your app.

* Calls run on Stream's global edge network for optimal latency & reliability.
* Permissions give you fine grained control over who can do what.
* Video quality and codecs are automatically optimized.


### Step 1 - Create a new project in Android Studio

1. Create a new project
2. Select Phone & Template -> **empty activity**
3. Name your project **VideoCall**.

Note that setup steps can vary slightly across Android Studio versions.
If you run into trouble be sure to use the latest version of Android Studio (Flamingo or higher).

### Step 2 - Install the SDK & Setup the client

**Add the Video Compose SDK** and [Jetpack Compose](https://developer.android.com/jetpack/compose) dependencies to your app's `build.gradle.kts` file found in `app/build.gradle`.
If you're new to android, note that there are 2 `build.gradle` files, you want to open the `build.gradle` in the app folder.

```groovy
dependencies {
    // Stream Video Compose SDK
    implementation("io.getstream:stream-video-android-compose:0.0.15-SNAPSHOT")

    // Jetpack Compose
    implementation(platform("androidx.compose:compose-bom:2023.06.00"))
    implementation("androidx.activity:activity-compose:1.7.2")
    implementation("androidx.compose.ui:ui")
    implementation("androidx.compose.ui:ui-tooling")
    implementation("androidx.compose.runtime:runtime")
    implementation("androidx.compose.foundation:foundation")
    implementation("com.google.android.material:material")
}
```

There are 2 versions of Stream's SDK.

- **Video Compose SDK**: `io.getstream:stream-video-android-compose` dependency that includes the video core SDK + compose UI components.
- **Video Core SDK**: `io.getstream:stream-video-android-core` that only includes the core parts of the video SDK.

For this tutorial, we'll use the compose UI components.

### Step 3 - Create & Join a call

Open up `MainActivity.kt` and replace the **MainActivity** class with:

```kotlin
class MainActivity : ComponentActivity() {
    override fun onCreate(savedInstanceState: Bundle?) {
        super.onCreate(savedInstanceState)

        val userId = "REPLACE_WITH_USER_ID"
        val userToken = "REPLACE_WITH_TOKEN"
        val callId = "REPLACE_WITH_CALL_ID"

        // step1 - create a user.
        val user = User(
            id = userId, // any string
            name = "Tutorial", // name and image are used in the UI
            role = "admin"
        )

        // step2 - initialize StreamVideo. For a production app we recommend adding the client to your Application class or di module.
        val client = StreamVideoBuilder(
             context = applicationContext,
             apiKey = "hd8szvscpxvd", // demo API key
             geo = GEO.GlobalEdgeNetwork,
             user = user,
             token = userToken,
        ).build()

        // step3 - join a call, which type is `default` and id is `123`.
        val call = client.call("default", callId)
        lifecycleScope.launch {
            call.join(create = true)
        }

        setContent {
            // step4 - apply VideoTheme
            VideoTheme {
                // step5 - define required properties.
                val participants by call.state.participants.collectAsState()
                val connection by call.state.connection.collectAsState()

                // step6 - render texts that display connection status.
                Box(
                    contentAlignment = Alignment.Center,
                    modifier = Modifier.fillMaxSize()
                ) {
                    if (connection != RealtimeConnection.Connected) {
                        Text("loading...", fontSize = 30.sp)
                    } else {
                        Text("Call ${call.id} has ${participants.size} participants", fontSize = 30.sp)
                    }
                }
            }
        }
    }
}
```

To run this sample we need a valid user token. The user token is typically generated by your server side API.
So when the user logs in for your app you return the user token that gives them access to video calling.
To make this tutorial easier to follow we'll generate a user token for you.

Please update **REPLACE_WITH_USER_ID**, **REPLACE_WITH_TOKEN** and **REPLACE_WITH_CALL_ID** with the actual values shown below:

<TokenSnippet sampleApp='meeting' />

Now when you run the sample app it will connect successfully.
The text will say "call ... has 1 participant" (yourself).
Let's review what we did in the above code.

**User** setup. First we create a user object.
You typically sync these users via a server side integration from your own backend.
Alternatively you can also use guest or anonymous users.
The user's role allows you to configure permissions in the video call.

```kotlin
val user = User(
    id = userId, // any string
    name = "Tutorial", // name and image are used in the UI
    role = "admin"
)
```

Next, we setup the video SDK and join the call.

```kotlin
val call = client.call("default", callId)
lifecycleScope.launch {
    call.join(create = true)
}
```

As soon as you use `call.join` the connection for video & audio is setup.

Last the UI looks up the StateFlow objects in `call.state`.

```kotlin
val participants by call.state.participants.collectAsState()
val connection by call.state.connection.collectAsState()
```

You'll find all relevant state for the call in `call.state` and `call.state.participants`.
The documentation on [Call state and Participant state](../03-guides/03-call-and-participant-state.mdx) explains this in further detail.

### Step 4 - Joining from the web

To make this a little more interactive let's join the call from your browser.

<TokenSnippet sampleApp='meeting' displayStyle='join' />

On your Android emulator you'll see the text update to 2 participants.
Let's keep the browser tab open as you go through the tutorial.

### Step 5 - Rendering Video

In this next step we're going to:

1. Request permissions (to capture video and audio)
2. Render your local & remote participant video

#### A. Requesting permissions

To capture the microphone and camera output we need to request [Android runtime permissions](https://source.android.com/docs/core/permissions/runtime_perms).
In MainActivity.kt just below setContent add the line `LaunchCallPermissions(call = call)`

```kotlin
setContent {
    LaunchCallPermissions(call = call)
    ...
}
```

The launch call permissions will request permissions when you open the call.
Review the [permissions docs](../05-ui-cookbook/08-permissions-request.mdx) to learn more about how you can easily request permissions.

#### B. Render the video

In the `MainActivity.kt` file, replace the code inside `setContent` code with the example below:

```kotlin
setContent {
    LaunchCallPermissions(call = call)

    VideoTheme {
        val remoteParticipants by call.state.remoteParticipants.collectAsState()
        val remoteParticipant = remoteParticipants.firstOrNull()
        val remoteVideo = remoteParticipant?.video?.collectAsState()
        val me by call.state.me.collectAsState()
        val connection by call.state.connection.collectAsState()
        var parentSize: IntSize by remember { mutableStateOf(IntSize(0, 0)) }

        Box(
            contentAlignment = Alignment.Center,
            modifier = Modifier
                .fillMaxSize()
                .background(VideoTheme.colors.appBackground)
                .onSizeChanged { parentSize = it }
        ) {
            if (remoteParticipant != null) {
                Column(modifier = Modifier.fillMaxSize()) {
                    VideoRenderer(
                        modifier = Modifier.weight(1f),
                        call = call,
                        video = remoteVideo?.value
                    )
                }
            } else {
                if (connection != RealtimeConnection.Connected) {
                    Text(
                        text = "loading...",
                        fontSize = 30.sp,
                        color = VideoTheme.colors.textHighEmphasis
                    )
                } else {
                    Text(
                        modifier = Modifier.padding(30.dp),
                        text = "Join call ${call.id} in your browser to see the video here",
                        fontSize = 30.sp,
                        color = VideoTheme.colors.textHighEmphasis,
                        textAlign = TextAlign.Center
                    )
                }
            }

            // floating video UI for the local video participant
            me?.let {
                FloatingParticipantVideo(
                    modifier = Modifier.align(Alignment.TopEnd),
                    call = call,
                    participant = it,
                    parentBounds = parentSize
                )
            }
        }
    }
}
```

Now when you run the app you'll see your local video in a floating video element and the video from your browser.
The end result should look somewhat like this:

![Video Tutorial](../assets/portrait-video-two.png)

Let's review the changes we made.

**VideoRenderer** is our main video rendering component.

```kotlin
VideoRenderer(
    modifier = Modifier.weight(1f),
    call = call,
    video = remoteVideo?.value
)
```

It only displays the video and doesn't add any other UI elements.
The video is lazily loaded, and only requested from the video infrastructure if you're actually displaying it.
So if you have a video call with 200 participants, and you show only 10 of them, you'll only receive video for 10 participants.
This is how software like Zoom and Google Meet make large calls work.

**FloatingParticipantVideo** renders a draggable display of your own video.

```kotlin
FloatingParticipantVideo(
    modifier = Modifier.align(Alignment.TopEnd),
    call = call,
    participant = me!!,
    parentBounds = parentSize
)
```

### Step 6 - A Full Video Calling UI

The above example showed how to use the call state object and compose to build a basic video UI.
For a production version of calling you'd want a few more UI elements:

* Indicators of when someone is speaking
* Quality of their network
* Layout support for >2 participants
* Labels for the participant names
* Call header and controls

Stream ships with several Compose components to make this easy.
You can customize the components with theming, arguments and swapping parts of them.
This is convenient if you want to quickly build a production ready calling experience for you app.
(and if you need more flexibility, many customers use the above low level approach to build a UI from scratch)

To render a full calling UI we'll leverage the `CallContainer` component.
This includes sensible defaults for a call header, video grid and call controls.

Open `MainActivity.kt` and setup the viewmodel at the top of the activity:

```kotlin

class MainActivity : ComponentActivity() {

    private val factory by lazy { CallViewModelFactory() }
    private val vm by viewModels<CallViewModel> { factory }

    ....

}
```

Next in the same file, update the code inside of `VideoTheme` to use the `CallContainer`.
The code will be a lot smaller than before since all UI logic is handled in the `CallContainer`:

```kotlin
VideoTheme {
    CallContainer(
        modifier = Modifier.fillMaxSize(),
        call = call,
        callViewModel = vm,
        onBackPressed = { onBackPressed() },
    )
}
```

The result will be:

![Compose CallContainer](../assets/compose_call_container.png)

When you now run your app you'll see a more polished video UI.
It supports reactions, screensharing, active speaker detection, network quality indicators etc.
The most commonly used UI components are:

* [VideoRenderer](../05-ui-cookbook/02-video-renderer.mdx): For rendering video and automatically requesting video tracks when needed.
* [ParticipantVideo](../04-ui-components/05-participants/01-participant-video.mdx): The participant's video + some UI elements for network quality, reactions, speaking etc.
* [ParticipantsGrid](../04-ui-components/05-participants/02-participants-grid.mdx): A grid of participant video elements.
* [FloatingParticipantVideo](../04-ui-components/05-participants/03-floating-participant-video.mdx): A draggable version of the participant video. Typically used for your own video.
* [ControlActions](../05-ui-cookbook/02-control-actions.mdx): Buttons for controlling your call.
* [RingingCallContent](../04-ui-components/04-call/02-ringing-call.mdx): UI for displaying an incoming call.

The full list of [UI components](../04-ui-components/01-overview.mdx) is available in the docs.

### Step 7 - Customizing the UI

You can customize the UI by:

* Building your own UI components (the most flexibility, build anything).
* Mixing and matching with Stream's UI Components (speeds up how quickly you can build common video UIs).
* Theming (basic customization of colors, fonts etc).

The example below shows how to swap out the call controls for your own controls:

```kotlin
override fun onCreate(savedInstanceState: Bundle?) {
    super.onCreate(savedInstanceState)

    lifecycleScope.launch { call.join(create = true) }

    setContent {
        VideoTheme {
            val isCameraEnabled by call.camera.isEnabled.collectAsState()
            val isMicrophoneEnabled by call.microphone.isEnabled.collectAsState()

            CallContainer(
                modifier = Modifier.background(color = VideoTheme.colors.appBackground),
                call = call,
                callViewModel = vm, // optional
                onBackPressed = { onBackPressed() },
                controlsContent = {
                    ControlActions(
                        call = call,
                        actions = listOf(
                            {
                                ToggleCameraAction(
                                    modifier = Modifier.size(52.dp),
                                    isCameraEnabled = isCameraEnabled,
                                    onCallAction = { call.camera.setEnabled(callAction.isEnabled) }
                                )
                            },
                            {
                                ToggleMicrophoneAction(
                                    modifier = Modifier.size(52.dp),
                                    isMicrophoneEnabled = isMicrophoneEnabled,
                                    onCallAction = { call.microphone.setEnabled(callAction.isEnabled) }
                                )
                            },
                            {
                                FlipCameraAction(
                                    modifier = Modifier.size(52.dp),
                                    onCallAction = { call.camera.flip() }
                                )
                            },
                        )
                    )
                }
            )
        }
    }
}
```

Stream's Video SDK provides fully polished UI components, allowing you to build a video call quickly and customize them. As you've seen before, you can implement a full complete video call screen with `CallContainer` composable in Jetpack Compose. The `CallContainer` composable consists of three major parts below:

- **appBarContent**: Content is shown that calls information or additional actions.
- **controlsContent**: Content is shown that allows users to trigger different actions to control a joined call.
- **callContent**: Content shown to be rendered when we're connected to a call successfully.

Theming gives you control over the colors and fonts.

```kotlin
VideoTheme(
    colors = StreamColors.defaultColors().copy(appBackground = Color.Black),
    dimens = StreamDimens.defaultDimens().copy(callAvatarSize = 72.dp),
    typography = StreamTypography.defaultTypography().copy(title1 = TextStyle()),
    shapes = StreamShapes.defaultShapes().copy(avatar = CircleShape)
) {
  ..
}
```

### Recap

Please do let us know if you ran into any issues.
Our team is also happy to review your UI designs and offer recommendations on how to achieve it with Stream.

To recap what we've learned:

* You setup a call: (val call = client.call("default", "123"))
* The call type ("default" in the above case) controls which features are enabled and how permissions are setup
* When you join a call, realtime communication is setup for audio & video calling: (call.join())
* Stateflow objects in call.state and call.state.participants make it easy to build your own UI
* VideoRenderer is the low level component that renders video

Calls run on Stream's global edge network of video servers.
By being closer to your users the latency and reliability of calls are better.
The SDKs enable you to build in-app video calling, audio rooms and livestreaming in days.

We hope you've enjoyed this tutorial and please do feel free to reach out if you have any suggestions or questions.
