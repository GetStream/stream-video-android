---
title: Livestream Tutorial
description: How to build a livestream experience using Stream's video SDKs
---

import { TokenSnippet } from '../../../shared/_tokenSnippet.jsx';

:::danger

This tutorial isn't ready yet
:::

## Notes other SDKs

- add .live as the opposite of .backstage
- expose ingress urls nicely (ingress.rtmp.address, ingress.rtmp.streamKey)
- expose duration based on session.liveSince

## TODO tutorial:

- split the first part of the tutorial

- request permissions

## TODO server:

- a way to mark a video as the primary/pinned video. if you have multiple hosts, how do you select the primary video?
- the session should have a field with the total participant count (since thats what you want to show most of the time). ideally SFU ParticipantCount and session data should follow the same structure
- session data isn't 100% correct. after 1 user joins it returns this in the CallSessionStartedEvent participantsCountByRole={}, rejectedBy={}, endedAt=null, startedAt=null
- CallSessionParticipantJoinedEvent and CallSessionStartedEvent are send in the wrong order
- CallParticipantResponse lacks a session id, so you can't easily add or remove from that list based on the events
- RTMP in ratio has some problems


## Livestream Tutorial

In this tutorial we'll quickly build a low-latency in-app livestreaming experience.
The livestream is broadcasted using Stream's edge network of servers around the world.
We'll cover the following topics:

* Ultra low latency streaming
* Multiple streams & co-hosts
* RTMP in and Webrtc input
* Exporting to HLS
* Reactions, custom events and chat
* Recording & Transcriptions

Let's get started, if you have any questions or feedback be sure to let us know via the feedback button.

### Step 1 - Create a new project in Android Studio

This tutorial was written using Android Studio Flamingo.
Setup steps can vary slightly across Android Studio versions so if you run into trouble be sure to use the latest version of Android Studio.

1. Create a new project
2. Select Phone & Template -> **empty activity**
3. Name your project **Livestream**.

### Step 2 - Install the SDK & Setup the client

**Add the video SDK** to your app's `build.gradle` file found in app/build.gradle
If you're new to android note that there are 2 build.gradle files, you want to open the one in the app folder.

```groovy
dependencies {
    implementation "io.getstream:stream-video-android-compose:$stream_version"
}
```

This tutorial uses the compose version of the SDK. Stream also provides a core library without compose.

### Step 3 - Publish from your phone


The following code shows how to publish from your phone's camera to the call.
Let's open MainActivity.kt and replace the MainActivity class with the following code:

```kotlin
class MainActivity : ComponentActivity() {
    override fun onCreate(savedInstanceState: Bundle?) {
        super.onCreate(savedInstanceState)

        val userToken = "REPLACE_WITH_TOKEN"
        val userId = "REPLACE_WITH_USER_ID"
        val callId = "REPLACE_WITH_CALL_ID"

        // create a user.
        val user = User(
            id = userId, // any string
            name = "Tutorial" // name and image are used in the UI
        )

        // for a production app we recommend adding the client to your Application class or di module.
        val client = StreamVideoBuilder(
            context = applicationContext,
            apiKey = "hd8szvscpxvd", // demo API key
            geo = GEO.GlobalEdgeNetwork,
            user = user,
            token = userToken,
        ).build()

        // join a call, which type is `default`
        val call = client.call("livestream", callId)
        lifecycleScope.launch {

            call.camera.enable()
            call.microphone.enable()

            // join the call
            val result = call.join(create = true)
            result.onError {
                Toast.makeText(applicationContext, "uh oh $it", Toast.LENGTH_SHORT).show()
            }
        }

        setContent {
            // enable the camera and microphone
            LaunchCallPermissions(call = call)
            VideoTheme {
                Text("TODO: render video")
            }
        }
    }
}

```

Let's review the above steps.

TODO: Review what we did here

### Step 4 - Render the video

```kotlin

VideoTheme {
    val participantCount = call.state.participantCounts.collectAsState().value?.total
    val connection by call.state.connection.collectAsState()
    val backstage by call.state.backstage.collectAsState()
    val me by call.state.me.collectAsState()
    val video = me?.video?.collectAsState()
    val session by call.state.session.collectAsState()

    Box(
        modifier = Modifier
            .fillMaxSize()
            .background(VideoTheme.colors.appBackground),
    ) {
        VideoRenderer(call = call, video = video?.value, videoFallbackContent = {

        })

        Column(
            verticalArrangement = Arrangement.Bottom,
            horizontalAlignment = Alignment.CenterHorizontally,
            modifier = Modifier.fillMaxWidth().fillMaxHeight().padding(32.dp)

        ) {


            if (connection == RealtimeConnection.Connected) {
                if (!backstage) {
                    Text("Livestream has $participantCount participants")

                    Text("Live for 1:23")
                }

                Button(onClick = {
                    lifecycleScope.launch {
                        if (backstage) call.goLive() else call.stopLive()
                    }
                }) {
                    Text(text = if (backstage) "Go Live" else "Stop Broadcast")
                }
            }
        }

    }
}
```

Before running the app please update **REPLACE_WITH_USER_ID**, **REPLACE_WITH_TOKEN** and **REPLACE_WITH_CALL_ID** with the actual values shown below:

<TokenSnippet sampleApp='livestream' displayStyle='credentials' />

With the updated token in place, run the app. You should see a screen like this:

TODO: Image

Now when you press live your video will be transmitted. You can confirm it by joining online here.

<TokenSnippet sampleApp='livestream' displayStyle='join' />

By default livestreams will start in the backstage mode. During the backstage mode only the host and co-hosts can join.
This is convenient for testing your camera setup etc. When you want to go live simply use call.goLive().
When the call is live regular users can join.


### Step 4 - (Optional) Publishing RTMP using OBS

The example above showed how to publish your phone's camera to the livestream. Almost all livestream software and hardware supports RTMPS.
So let's see how to publish using RTMPs. Feel free to skip this step if you don't need to use RTMPs.

A. Console log the URL & Stream Key println(call.state.ingress.rtmp)

B. Open OBS and go to settings -> stream
- Select "custom" service
- Server: equal to the server URL from the console log
- Stream key: equal to the stream key from the console log

Press start streaming. The RTMP stream will now show up in your call.
Now that we've learned to publish using webrtc or RTMP let's talk about viewing the livestream.

### Step 5 - Viewing a livestream (Webrtc)

The client setup for someone watching the call is quite similar.

```kotlin
// anonymous user
val client = StreamVideoBuilder(
    context = applicationContext,
    apiKey = "hd8szvscpxvd", // demo API key
    geo = GEO.GlobalEdgeNetwork,
    user = User(
       type = UserType.Anonymous
   ),
).build()

// mute volume by default
call.speaker.setVolume(0)
```

Here's the update MainActivity for viewing a call

```kotlin
```

### Step 6 - (Optional) Viewing a livestream with HLS

Another way to view a livestream is using HLS. HLS tends to have a 10 to 20 seconds delay, while the above webrtc approach only has a 100-200ms delay typically.
The benefit that HLS has is that it buffers better under poor network conditions.
So for apps where you expect your users to have poor network, and where a 10 second delay is ok, HLS can be a better option.

Let's show how to broadcast your call to HLS.

```kotlin
call.startBroadcast()
```

After starting the broadcast the HLS url can be found in the call state

```kotlin
call.state.egress.value?.hls
```

You can view the HLS video feed using any open source HLS capable video player.

### 7 - Advanced Features

There are several advanced features that can improve the livestreaming experience:

* ** Co-hosts ** You can add members to your livestream with elevated permissions. So you can have co-hosts, moderators etc.
* ** Custom events ** You can use custom events on the call to share any additional data. Think about showing the score for a game, or any other realtime use case.
* ** Reactions & Chat ** Users can react to the livestream, and you can add chat. This makes for a more engaging experience.
* ** Notifications ** You can notify users via push notifications when the livestream starts
* ** Recording ** The call recording functionality allows you to record the call with various options and layouts

### Recap

It was fun to see just how quickly you can build in-app low latency livestreaming.
Please do let us know if you ran into any issues.
Our team is also happy to review your UI designs and offer recommendations on how to achieve it with Stream.

To recap what we've learned:

* Webrtc is optimal for latency, HLS is slower but buffers better for users with poor connections
* You setup a call: (val call = client.call("livestream", callId))
* The call type "livestream" controls which features are enabled and how permissions are setup
* The livestream by default enables "backstage" mode. This allows you and your co-hosts to setup your mic and camera before allowing people in
* When you join a call, realtime communication is setup for audio & video: (call.join())
* Stateflow objects in call.state and call.state.participants make it easy to build your own UI
* For a livestream the most important one is call.state.???

Calls run on Stream's global edge network of video servers.
Being closer to your users improves the latency and reliability of calls.
The SDKs enable you to build livestreaming, audio rooms and video calling in days.

We hope you've enjoyed this tutorial and please do feel free to reach out if you have any suggestions or questions.