---
title: How to Build an Android Audio Room with Kotlin
description: How to build an audio room using Stream's video SDKs
---

import { TokenSnippet } from '../../../shared/_tokenSnippet.jsx';

This tutorial will teach you how to build an audio room experience like Twitter Spaces or Clubhouse.
The end result will look like the image on the right and support the following features:

* Backstage mode. You can start the call with your co-hosts and chat a bit before going live
* Calls run on Stream's global edge network for optimal latency and scalability
* There is no cap to how many listeners you can have in a room
* Listeners can raise their hand, and be invited to speak by the host
* Audio tracks are send multiple times for optimal reliability

![Audio Room](../assets/audio-room.png)

Time to get started building an audio-room for your app.

### Step 1 - Create a new project in Android Studio

This tutorial was written using Android Studio Flamingo.
Setup steps can vary slightly across Android Studio versions.
If you run into trouble be sure to use the latest version of Android Studio.

1. Create a new project
2. Select Phone & Template -> **Empty Activity**
3. Name your project **AudioRoom**.

### Step 2 - Install the SDK & Setup the client

**Add the Video Compose SDK** and [Jetpack Compose](https://developer.android.com/jetpack/compose) dependencies to your app's `build.gradle.kts` file found in `app/build.gradle`.
If you're new to android, note that there are 2 `build.gradle` files, you want to open the `build.gradle` in the app folder.

```groovy
dependencies {
    // Stream Video Compose SDK
    implementation("io.getstream:stream-video-android-compose:0.0.18")

    // Jetpack Compose (optional/ android studio typically adds them when you create a new project)
    implementation(platform("androidx.compose:compose-bom:2023.06.00"))
    implementation("androidx.activity:activity-compose:1.7.2")
    implementation("androidx.compose.ui:ui")
    implementation("androidx.compose.ui:ui-tooling")
    implementation("androidx.compose.runtime:runtime")
    implementation("androidx.compose.foundation:foundation")
    implementation("com.google.android.material:material")
}
```

There are 2 versions of Stream's SDK.

- **Video Compose SDK**: `io.getstream:stream-video-android-compose` dependency that includes the video core SDK + compose UI components.
- **Video Core SDK**: `io.getstream:stream-video-android-core` that only includes the core parts of the video SDK.

For this tutorial, we'll use the compose UI components.

### Step 3 - Create & Join a call

Open up `MainActivity.kt` and replace the **MainActivity** class with the following code:

```kotlin
class MainActivity : ComponentActivity() {
    override fun onCreate(savedInstanceState: Bundle?) {
        super.onCreate(savedInstanceState)

        val userId = "REPLACE_WITH_USER_ID"
        val userToken = "REPLACE_WITH_TOKEN"
        val callId = "REPLACE_WITH_CALL_ID"

        // step1 - create a user.
        val user = User(
            id = userId, // any string
            name = "Tutorial", // name and image are used in the UI
            role = "admin"
        )

        // step2 - initialize StreamVideo. For a production app we recommend adding the client to your Application class or di module.
        val client = StreamVideoBuilder(
            context = applicationContext,
            apiKey = "6s726ystmnqa", // demo API key
            geo = GEO.GlobalEdgeNetwork,
            user = user,
            token = userToken,
        ).build()

        // step3 - join a call, which type is `audio_room` and id is `123`.
        val call = client.call("audio_room", callId)
        lifecycleScope.launch {
            val result = call.join(create = true, createOptions = CreateCallOptions(
                members = listOf(
                    MemberRequest(userId = "tommaso", role="moderator", custom = emptyMap()),
                    MemberRequest(userId = "thierry", role="moderator", custom = emptyMap())
                ), custom = mapOf(
                    "title" to "Compose Trends",
                    "description" to "Talk about how easy compose makes it to reuse and combine UI"
                )
            ))
            result.onError {
                Toast.makeText(this, it.message, Toast.LENGTH_SHORT).show()
            }
        }

        setContent {
            Text("nothing here just yet")
        }
    }
}
```

Let's review the example above and go over the details.

**User** setup. First we create a user object.
You typically sync your users via a server side integration from your own backend.
Alternatively, you can also use guest or anonymous users.
The user's role allows you to configure permissions in the video call.

```kotlin
val user = User(
    id = userId, // any string
    name = "Tutorial", // name and image are used in the UI
    role = "admin"
)
```

**Client init**. Next we initialize the client by passing the API Key, user and user token.

```kotlin
 val client = StreamVideoBuilder(
    context = applicationContext,
    apiKey = "6s726ystmnqa", // demo API key
    geo = GEO.GlobalEdgeNetwork,
    user = user,
    token = userToken,
).build()
```
**Create and join call** After the user and client are created, we create a call like this:

```kotlin
val call = client.call("audio_room", callId)
lifecycleScope.launch {
    val result = call.join(create = true, createOptions = CreateCallOptions(
        members = listOf(
            MemberRequest(userId = "jack", role="moderator", custom = emptyMap()),
            MemberRequest(userId = "sophia", role="moderator", custom = emptyMap())
        ), custom = mapOf(
            "title" to "Compose Trends",
            "description" to "Talk about how easy compose makes it to reuse and combine UI"
        )
    ))
}
```

* This joins and creates a call with the type: "audio_room" and the specified callId
* The users with id jack and sophia are added as moderators
* And we set the `title` and `description` custom field on the call object

To actually run this sample we need a valid user token. The user token is typically generated by your server side API.
When a user logs in to your app you return the user token that gives them access to the call.
To make this tutorial easier to follow we'll generate a user token for you:

Please update **REPLACE_WITH_USER_ID**, **REPLACE_WITH_TOKEN** and **REPLACE_WITH_CALL_ID** with the actual values shown below:

<TokenSnippet sampleApp='audio-rooms' />

With valid credentials in place, we want to actually render the first parts of our audio-room.
Open up `MainActivity.kt` and replace the setContent function with the following:

```kotlin

setContent {
    // step4 - apply VideoTheme
    VideoTheme {
        // step5 - define required properties.
        val custom by call.state.custom.collectAsState()
        val title = custom["title"]
        val description = custom["description"]
        val participants by call.state.participants.collectAsState()
        val connection by call.state.connection.collectAsState()

        // step6 - render texts that display connection status.
        Column(horizontalAlignment = Alignment.CenterHorizontally, modifier = Modifier.padding(16.dp)) {
            if (connection != RealtimeConnection.Connected) {
                Text("loading", fontSize = 30.sp)
            } else {
                Text("$title", fontSize = 30.sp)
                Text("$description", fontSize = 20.sp, modifier = Modifier.padding(16.dp))
                Text("${participants.size} participants", fontSize = 20.sp)
            }
        }
    }
}

```

Now when you run the sample app it will connect successfully and you will see a room with 1 participant (yourself).

### Step 4 - Adding audio room UI elements

In this next step we're going to:

1. Request Android Runtime permissions (audio)
2. Mute and Unmute microphone toggle button
2. Create a list of participants
3. An indicator for who's speaking

#### A. Requesting Android Runtime Permissions

To capture the microphone output we need to request [Android runtime permissions](https://source.android.com/docs/core/permissions/runtime_perms).
In `MainActivity.kt` just below `setContent` add the line `LaunchMicrophonePermissions(call = call)`

```kotlin
setContent {
    LaunchMicrophonePermissions(call = call)
    ...
}
```

The launch call permissions will request permissions when you open the call.
Review the [permissions docs](../05-ui-cookbook/08-permissions-request.mdx) to learn more about how you can easily request permissions.

#### B. Add a toggle button to mute/unmute microphone

Next, let's create a toggle button to mute and unmute a microphone.

You can simply connect the state of a microphone toggle button with the call's device manager with using `ToggleMicrophoneAction` and `call.microphone`:

```kotlin
val isMicrophoneEnabled by call.microphone.isEnabled.collectAsState()

ToggleMicrophoneAction(
    modifier = Modifier.size(52.dp),
    isMicrophoneEnabled = isMicrophoneEnabled,
    onCallAction = { call.microphone.setEnabled(it.isEnabled) }
)
```

#### C. Create a list of participants

Let's create a component for the active speaker and the list of participants.

```kotlin

@Composable
fun ParticipantAvatar(participant : ParticipantState) {
    val user by participant.user.collectAsState()
    Text("${user.name} - ${user.role}")
}
```

#### D. An indicator for who's speaking

We'll use the basic `ParticipantAvatar` to build an audio room:

```kotlin
setContent {
    LaunchMicrophonePermissions(call = call)

    VideoTheme {
        val connection by call.state.connection.collectAsState()
        val custom by call.state.custom.collectAsState()
        val title = custom["title"]
        val description = custom["description"]
        val participants by call.state.participants.collectAsState()
        val dominantSpeaker by call.state.dominantSpeaker.collectAsState()
        val sortedParticipants by call.state.sortedParticipants.collectAsState()
        val otherParticipants = sortedParticipants.filter { it != dominantSpeaker }
        val audioLevel = dominantSpeaker?.audioLevel?.collectAsState()?.value ?: 0f
        val backstage by call.state.backstage.collectAsState()

        val color1 = Color.LightGray.copy(alpha = 0.2f+ audioLevel * 0.8f)
        val color2 = Color.White.copy(alpha = 0.2f+ audioLevel * 0.8f)

        Column(
            horizontalAlignment = Alignment.CenterHorizontally,
            modifier = Modifier.background(Brush.linearGradient(listOf(color1, color2))).fillMaxSize()
        ) {
            if (connection != RealtimeConnection.Connected) {
                Text("loading", fontSize = 30.sp)
            } else {
                Text("$title", fontSize = 30.sp)
                Text("$description", fontSize = 20.sp, modifier = Modifier.padding(16.dp))
                Text("${participants.size} participants", fontSize = 20.sp)
            }

            dominantSpeaker?.let {
                Text("${it.user.value.name} is speaking")
            }

            LazyVerticalGrid(
                columns = GridCells.Adaptive(minSize = 128.dp)
            ) {
                items(otherParticipants.size) { index ->
                    val participant = otherParticipants[index]
                    ParticipantAvatar(participant)
                }
            }

            val isMicrophoneEnabled by call.microphone.isEnabled.collectAsState()
            ToggleMicrophoneAction(
                modifier = Modifier.size(52.dp),
                isMicrophoneEnabled = isMicrophoneEnabled,
                onCallAction = { call.microphone.setEnabled(it.isEnabled) }
            )

            Button(
                onClick = {
                    lifecycleScope.launch {
                        if (backstage) call.goLive() else call.stopLive()
                    }
                }) {
                Text(text = if (backstage) "Go Live" else "End")
            }
        }
    }
}
```

See how speaking changes the `audioLevel` and updates the background.

Run the sample app now and you'll see 1 participant.
Click the go live button to allow participants to join.

### Step 5 - Joining from the web

To make this a little more interactive let's join the call from your browser.

<TokenSnippet sampleApp='audio-rooms' displayStyle='join' />

On your Android emulator you'll see the text update to 2 participants.
Let's keep the browser tab open as you go through the tutorial.

### Step 6 - AudioRoom UI

We can improve the UI for the audio room participants.
The [participantState docs](../03-guides/03-call-and-participant-state.mdx) exposes all the state objects we need for the name, avatar, audio levels, speaking etc.
Open `MainActivity.kt` and replace the ParticipantAvatar with the following:

```kotlin
@Composable
public fun ParticipantAvatar(
    participant: ParticipantState,
    modifier: Modifier = Modifier
) {
    val user by participant.user.collectAsState()
    val nameOrId by participant.userNameOrId.collectAsState()
    val isSpeaking by participant.speaking.collectAsState()
    val audioEnabled by participant.audioEnabled.collectAsState()

    Column(
        modifier = modifier,
        horizontalAlignment = Alignment.CenterHorizontally,
        verticalArrangement = Arrangement.Center
    ) {

        Box(modifier = Modifier.size(VideoTheme.dimens.audioAvatarSize)) {
            UserAvatar(
                user = user,
                modifier = Modifier
                    .fillMaxSize()
                    .padding(VideoTheme.dimens.audioAvatarPadding)
            )

            if (isSpeaking) {
                Box(
                    modifier = Modifier
                        .fillMaxSize()
                        .border(style.speakingBorder, CircleShape)
                )
            } else if (!audioEnabled) {
                Box(
                    modifier = Modifier
                        .fillMaxSize()
                        .padding(VideoTheme.dimens.audioAvatarPadding)
                ) {
                    Box(
                        modifier = Modifier
                            .clip(CircleShape)
                            .background(VideoTheme.colors.appBackground)
                            .size(VideoTheme.dimens.audioRoomMicSize)
                    ) {
                        Icon(
                            modifier = Modifier
                                .fillMaxSize()
                                .padding(VideoTheme.dimens.audioRoomMicPadding),
                            painter = painterResource(id = io.getstream.video.android.ui.common.R.drawable.stream_video_ic_mic_off),
                            tint = VideoTheme.colors.errorAccent,
                            contentDescription = null
                        )
                    }
                }
            }
        }

        Spacer(modifier = Modifier.height(8.dp))

        Text(
            modifier = Modifier.fillMaxWidth(),
            text = nameOrId,
            fontSize = 14.sp,
            fontWeight = FontWeight.Bold,
            color = VideoTheme.colors.textHighEmphasis,
            textAlign = TextAlign.Center,
            overflow = TextOverflow.Ellipsis,
            maxLines = 1,
        )

        Row(
            modifier = Modifier.fillMaxWidth(),
            verticalAlignment = Alignment.CenterVertically
        ) {
            TODO: ROLE

            Text(
                modifier = Modifier.fillMaxWidth(),
                text = user.role,
                fontSize = 11.sp,
                color = VideoTheme.colors.textHighEmphasis,
                textAlign = TextAlign.Center,
                overflow = TextOverflow.Ellipsis,
                maxLines = 1,
            )
        }
    }
}
```

In the above example we use the following state flow objects:

```kotlin
val user by participant.user.collectAsState()
val nameOrId by participant.userNameOrId.collectAsState()
val isSpeaking by participant.speaking.collectAsState()
val audioEnabled by participant.audioEnabled.collectAsState()
```

The [ParticipantState docs](../03-guides/03-call-and-participant-state.mdx) include all the other attributes that are also available.
For audio rooms `participant.audioLevel` and `participant.audioLevels` can be convenient.


### Step 7 - Requesting permission to speak

The permission system makes it easy to request permission to join a room, enable audio, enable video, screenshare etc.
Requesting permission to speak is shown in the example below.

```kotlin
val response = call.requestPermissions("send-audio")
// and next the admin will call
val requests by call.state.permissionRequests
request.forEach {
    it.grant() // or it.reject()
}
```

Showing the UI for requesting and granting permissions is left as an exercise for the reader.

### Other built-in features

There are a few more exciting features that you can use to build audio rooms:

- ** Query Calls **: You can query calls to easily show upcoming calls, calls that recently finished etc
- ** Call Previews **: Before you join the call you can observe the participants and show a preview
- ** Reactions & Custom events **: Reactions and custom events are supported
- ** Recording & Broadcasting **: You can record your calls
- ** Chat **: Stream's chat SDKs are fully featured and you can integrate them in the call
- ** Moderation **: Moderation capabilities are built-in to the product
- ** Transcriptions **: Transcriptions aren't available yet, but they are due to launch soon

### Recap

It was fun to see just how quickly you can build an audio-room for your app.
Please do let us know if you ran into any issues.
Our team is also happy to review your UI designs and offer recommendations on how to achieve it with Stream.

To recap what we've learned:

* You setup a call: (val call = client.call("audio_room", "222"))
* The call type "audio_room" controls which features are enabled and how permissions are setup
* The audio_room by default enables "backstage" mode, and only allows admins to join before the call goes live
* When you join a call, realtime communication is setup for audio & video calling: (call.join())
* Stateflow objects in call.state and call.state.participants make it easy to build your own UI

Calls run on Stream's global edge network of video servers.
Being closer to your users improves the latency and reliability of calls.
For audio rooms we use Opus RED and Opus DTX for optimal audio quality.

The SDKs enable you to build audio rooms, video calling and livestreaming in days.

We hope you've enjoyed this tutorial and please do feel free to reach out if you have any suggestions or questions.
