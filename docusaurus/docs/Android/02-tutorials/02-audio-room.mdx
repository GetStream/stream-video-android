---
title: Audio Room Tutorial
description: How to build an audio room using Stream's video SDKs
---

## Audio Room Tutorial

This tutorial will teach you how to build an audio room experience like Twitter Spaces or Clubhouse.

* Backstage mode. You can start the call with your co-hosts and chat a bit before going live
* Calls run on Stream's global edge network for optimal latency and scalability
* There is no cap to how many listeners you can have in a room
* Listeners can raise their hand, and be invited to speak by the host
* Audio tracks are send multiple times for optimal reliability

Time to get started

### Step 1 - Create a new project in android studio

Note that this tutorial was written using Android Studio Flamingo.
Setup steps can vary slightly across Android Studio versions so if you run into trouble be sure to use the latest version of Android Studio.

* Create a new project
* Select "empty activity"
* Name your project "AudioRoom"

### Step 2 - Install the SDK & Setup the client

** Add the compose SDK ** to your app's build.gradle file found in app/build.gradle
If you're new to android note that there are 2 build.gradle files, you want to open the one in the app folder.

```groovy
dependencies {
    implementation "io.getstream:stream-video-android-compose:0.0.14-SNAPSHOT"
}
```

### Step 3 - Create & Join a call

Open up `MainActivity.kt` and replace the MainActivity class with the following code:

```kotlin
class MainActivity : ComponentActivity() {
    override fun onCreate(savedInstanceState: Bundle?) {
        super.onCreate(savedInstanceState)

        // create a user.
        val user = User(
            id = "tutorial@getstream.io", // any string
            name = "Tutorial", // name and image are used in the UI
            role = "admin"
        )

        // for a production app we recommend adding the client to your Application class or di module.
        val client = StreamVideoBuilder(
            context = applicationContext,
            apiKey = "hd8szvscpxvd", // demo API key
            geo = GEO.GlobalEdgeNetwork,
            user = user,
            token = "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VyX2lkIjoidHV0b3JpYWxAZ2V0c3RyZWFtLmlvIiwiaXNzIjoicHJvbnRvIiwic3ViIjoidXNlci90dXRvcmlhbEBnZXRzdHJlYW0uaW8iLCJpYXQiOjE2ODYyMTcwMzgsImV4cCI6MTY4NjIyNzg0M30.ufQrfKUUBA_ikSWlOFfjOVlyWeWfI3hTBABN14bBV_g",
        ).build()

        // join a call, which type is `default` and id is `123`.
        val call = client.call("audio_room", "444")
        lifecycleScope.launch {
            val result = call.join(create = true, createOptions = CreateCallOptions(
                members = listOf(
                    MemberRequest(userId = "tommaso", role="moderator", custom = emptyMap()),
                    MemberRequest(userId = "thierry", role="moderator", custom = emptyMap())
                ), custom = mapOf(
                    "title" to "Compose Trends",
                    "description" to "Talk about how easy compose makes it to reuse and combine UI"
                )
            ))
        }

        setContent {
            VideoTheme {
                val custom by call.state.custom.collectAsState()
                val title = custom["title"]
                val description = custom["description"]
                val participants by call.state.participants.collectAsState()
                val connection by call.state.connection.collectAsState()

                Column(horizontalAlignment = Alignment.CenterHorizontally, modifier = Modifier.padding(16.dp)) {
                    if (connection != RealtimeConnection.Connected) {
                        Text("loading", fontSize = 30.sp)
                    } else {
                        Text("$title", fontSize = 30.sp)
                        Text("$description", fontSize = 20.sp, modifier = Modifier.padding(16.dp))
                        Text("${participants.size} participants", fontSize = 20.sp)
                    }
                }
            }
        }
    }
}
```

Run the app you will see a room with 1 participant (yourself).
Let's review the example above and go over the details.
After the user and client are created, we setup a call like this:

```kotlin
val call = client.call("audio_room", "444")
lifecycleScope.launch {
    val result = call.join(create = true, createOptions = CreateCallOptions(
        members = listOf(
            MemberRequest(userId = "tommaso", role="moderator", custom = emptyMap()),
            MemberRequest(userId = "thierry", role="moderator", custom = emptyMap())
        ), custom = mapOf(
            "title" to "Compose Trends",
            "description" to "Talk about how easy compose makes it to reuse and combine UI"
        )
    ))
}
```

This example shows how to create and join a call with one API call.
It creates a call of type "audio_room", id "444" and makes the user ids "tommaso" and "thierry" moderators of the call.
In addition to that it also stores the title and description of the room in the custom data of the call object.

By default calls of type "audio_room" start with backstage mode enabled.
Admins and moderators can join the call. Regular users can only join the call when you go live.
This gives an opportunity to setup the audio/video etc before inviting people in.

### Step 4 - Adding audio room UI elements

In this next step we'll add:

* A list of participants
* An indicator for who's speaking

Let's create a component for the active speaker and the list of participants.

```kotlin
@Composable
fun DominantSpeaker(participant : ParticipantState?) {
    val user = participant?.user?.collectAsState()?.value
    Text("${user?.name} - ${user?.role}")
}

@Composable
fun ParticipantAvatar(participant : ParticipantState?) {
    val user = participant?.user?.collectAsState()?.value
    Text("${user?.name} - ${user?.role}")
}
```

We'll combine the ParticipantAvatar and DominantSpeaker into the UI for an audio room:

```kotlin
setContent {
    VideoTheme {
        val connection by call.state.connection.collectAsState()
        val custom by call.state.custom.collectAsState()
        val title = custom["title"]
        val description = custom["description"]
        val participants by call.state.participants.collectAsState()
        val dominantSpeaker by call.state.dominantSpeaker.collectAsState()
        val sortedParticipants by call.state.sortedParticipants.collectAsState()
        val otherParticipants = sortedParticipants.filter { it != dominantSpeaker }
        val audioLevel = dominantSpeaker?.audioLevel?.collectAsState()?.value ?: 0f
        val backstage by call.state.backstage.collectAsState()

        val color1 = Color.LightGray.copy(alpha = 0.2f+ audioLevel * 0.8f)
        val color2 = Color.White.copy(alpha = 0.2f+ audioLevel * 0.8f)

        Column(horizontalAlignment = Alignment.CenterHorizontally, modifier = Modifier.background(Brush.linearGradient(listOf(color1, color2)))
            .fillMaxSize()) {
            if (connection != RealtimeConnection.Connected) {
                Text("loading", fontSize = 30.sp)
            } else {
                Text("$title", fontSize = 30.sp)
                Text("$description", fontSize = 20.sp, modifier = Modifier.padding(16.dp))
                Text("${participants.size} participants", fontSize = 20.sp)
            }

            DominantSpeaker(dominantSpeaker)
            LazyVerticalGrid(
                columns = GridCells.Adaptive(minSize = 128.dp)
            ) {
                items(otherParticipants.size) { index ->
                    val participant = otherParticipants[index]
                    ParticipantAvatar(participant)
                }
            }
            Button(onClick = {
                lifecycleScope.launch {
                    if (backstage) call.goLive() else call.stopLive()
                }
            }) {
                Text(text = if (backstage)"Go Live" else "End")
            }
        }
    }
}
```

See how speaking changes the audioLevel and updates the background.

Run the sample app now and you'll see 1 participant.
Click the go live button to allow participants to join.

To make this a little more interactive let's join the call from your browser.
Visit https://getstream.io/video/demos/?id=444&skip-intro=1 and join the call.
On your Android emulator you'll see the text update to 2 participants.

### Step 5 - Adding audio room UI elements

In the last step the UI for DominantSpeaker and ParticipantAvatar was a bit limited.
Let's improve the design here.


TODO

### Step 6 - Requesting permission to speak

Requesting permission to speak is easy.

```kotlin
val response = call.requestPermissions("send-audio")
// and next the admin will call
val requests = call.state.permissionRequests.value
request.forEach {
    it.grant() // or it.reject()
}
```

### Other built-in features

There are a few more exciting features that you can use to build audio rooms

** Query Calls ** You can query calls to easily show upcoming calls, calls that recently finished etc.
** Reactions & Custom events ** Reactions and custom events are supported.
** Recording & Broadcasting ** You can record your calls
** Chat ** Stream's chat SDKs are fully featured and you can integrate them in the call
** Moderation ** Moderation capabilities are built-in to the product
** Transcriptions ** Transcriptions aren't available yet, but they are due to launch soon

### Recap

It was fun to see just how quickly you can build an audio-room for your app.
Please do let us know if you ran into any issues.
Our team is also happy to review your UI designs and offer recommendations on how to achieve it with Stream.

To recap what we've learned:

* You setup a call: (val call = client.call("audio_room", "222"))
* The call type "audio_room" controls which features are enabled and how permissions are setup
* The audio_room by default enables "backstage" mode, and only allows admins to join before the call goes live
* When you join a call, realtime communication is setup for audio & video calling: (call.join())
* Stateflow objects in call.state and call.state.participants make it easy to build your own UI

Calls run on Stream's global edge network of video servers.
Being closer to your users improves the latency and reliability of calls.
For audio rooms we use Opus RED and Opus DTX for optimal audio quality.

The SDKs enable you to build audio rooms, video calling and livestreaming in days.

We hope you've enjoyed this tutorial and please do feel free to reach out if you have any suggestions or questions.
